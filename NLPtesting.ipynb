{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7925bff8-9d72-4d61-934e-036e8a693d1e",
   "metadata": {},
   "source": [
    "# Quick instruction on NLP testing for DS Group project\n",
    "\n",
    "## Where to find Datasets\n",
    "- SentFin Dataset https://github.com/pyRis/SEntFiN/tree/main\n",
    "- Any financial dataset on Huggingface\n",
    "\n",
    "\n",
    "## Huggingface Models\n",
    "- FinBert https://huggingface.co/ProsusAI/finbert\n",
    "- FinanceSentClassification https://huggingface.co/RashidNLP/Finance-Sentiment-Classification\n",
    "- Deepseek R1 Distill Qwen 7b https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
    "- Deepseek R1 Distill Qwen 1.5b <strong>(Use this if you can't use 7b)</strong> https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "- 8b is similar to 7b and worth for testing, however I strongly recommend to test also on webbrowser version, with reasoning it is 671b version\n",
    "- Also don't forget ChatGPT on webbrowser (there is a GPT2 version on huggingface if you are interested testing it)\n",
    "\n",
    "## How to deploy them on local machine\n",
    "- Use Ollama https://ollama.com/\n",
    "- Or use LM Studio https://lmstudio.ai/\n",
    "- Or eventually deploy them on python-openai-transformer library, for example https://huggingface.co/RashidNLP/Finance-Sentiment-Classification?library=transformers, you may refer to the <strong>\"How to use the model\"</strong> as well\n",
    "- If you are deploying using libraries, make sure you read documentation before deployment, the functions and callbacks are very different for each of the models\n",
    "\n",
    "## How to test them (and test them in a good way)\n",
    "- Ollama and LM Studio come with GUIs, so you may test labelled data directly through them. But it is\n",
    "- Use on Ollama https://huggingface.co/docs/hub/en/ollama\n",
    "- Use on from LM Studio https://huggingface.co/blog/yagilb/lms-hf\n",
    "- Use APIs from both Ollama and LM Studion to call them in python (Send Prompt, receive message) https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "- Or directly using python openai or transformer libraries, you have to refer to each of the model instructions on huggingface\n",
    "- Don't forget to test if the models support structured data output (JSON for example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca00d2-e34b-437e-9a9b-c3b97ac2f121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
